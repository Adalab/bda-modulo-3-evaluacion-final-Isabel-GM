## üìä An√°lisis inicial de .describe().T` del dataset `Customer Flight Activity`

La exploraci√≥n con `df_flight.describe().T` aporta informaci√≥n muy √∫til para entender la distribuci√≥n general de las variables num√©ricas del dataset.

---------------------

## ‚úÖ Principales insights detectados:

# 1. Distribuciones generales
- Flights Booked: Media = 4.12, Mediana = 1.00 ‚Üí Distribuci√≥n asim√©trica. La mayor√≠a de clientes reserva pocos vuelos, pero hay algunos con muchos vuelos (m√°x: 21).
- Flights with Companions: Similar patr√≥n, con una media baja (1.03) y m√°ximos altos (hasta 11).
- Points Redeemed y Dollar Cost Points Redeemed: Tienen medias bajas pero desviaciones est√°ndar muy altas -> algunos clientes redimen much√≠simos puntos.

# 2. Valores cero frecuentes
- Varias columnas como `Flights Booked`, `Distance`, `Points Redeemed` y `Dollar Cost Points Redeemed` tienen **m√≠nimos en 0**, lo que puede reflejar meses sin actividad para algunos clientes.

# 3. Rango y outliers
- Algunas columnas muestran valores extremos, como:
  - `Points Redeemed`: hasta 876 puntos redimidos.
  - `Dollar Cost Points Redeemed`: m√°ximo de 71$, muy por encima del percentil 75 (que es 0.00).

# 4. Validaci√≥n de datos de fecha
- `Year`: media = 2017.5, m√≠nimo = 2017, m√°ximo = 2018 ‚Üí confirman que los datos corresponden a solo dos a√±os.
- `Month`: de 1 a 12, con media de 6.

---------------------------

### ‚ÑπÔ∏è Exploraci√≥n con `.info()` del dataset `Customer Flight Activity`

La funci√≥n `df_flight.info()` nos proporciona una visi√≥n general de la estructura del dataset. A continuaci√≥n se detallan los principales puntos observados:

---

# ‚úÖ Tama√±o del dataset
- **405.624 filas** y **10 columnas** ‚Üí un dataset amplio, con un buen volumen de informaci√≥n para analizar.

# ‚úÖ Valores nulos
- Todas las columnas tienen **405.624 valores no nulos**, por lo tanto:
  - **No hay valores nulos** en este dataset.
  - No se requiere tratamiento de nulos en esta fase.

# ‚úÖ Tipos de datos (`dtype`)
- **9 columnas** tienen tipo de dato `int64`.
- **1 columna** (`Points Accumulated`) es `float64`, lo cual es l√≥gico ya que puede tener valores decimales.
- Confirmamos que los decimales est√°n representados correctamente con `punto (.)`, como espera Python.

# ‚úÖ Memoria
- El DataFrame ocupa aproximadamente **30.9 MB en memoria**, lo cual es razonable para su tama√±o.

---

## üß† Conclusi√≥n
Los datos est√°n **completos y correctamente tipados**, lo cual nos permite pasar sin problemas a la siguiente fase: exploraci√≥n visual, an√°lisis de valores extremos o uni√≥n con otros datasets.

----------------------------------

## üìë Duplicados en el dataset `Customer Flight Activity`

Se detectaron **1864 filas duplicadas**.  
Esto significa que existen **1864 registros que son id√©nticos en todas las columnas**.

---

## ‚úÖ Opciones para tratar los duplicados

# 1. Mantener los duplicados
- Puede ser v√°lido si los datos duplicados reflejan situaciones reales repetidas (por ejemplo, vuelos m√∫ltiples del mismo tipo).
- Aun as√≠, es recomendable dejar constancia de que los duplicados existen y han sido analizados.

# 2. Eliminar los duplicados
- Si se asume que estas repeticiones no aportan valor o distorsionan el an√°lisis estad√≠stico, pueden eliminarse f√°cilmente con:

---

*** An√°lisis detallado de filas duplicadas ***

Uso  df_flight[df_flight.duplicated()].value_counts() para identificar exactamente cu√°les son las filas duplicadas dentro del dataset Customer Flight Activity.

- Resultado observado:

Se identificaron 1848 combinaciones de filas duplicadas, lo que representa un total de 1864 filas repetidas.
Estas duplicaciones afectan a m√∫ltiples clientes, no solo a uno.
La mayor√≠a de estas filas contienen valores en cero en todas las columnas de actividad:
Flights Booked = 0
Distance = 0
Points Accumulated = 0
Dollar Cost Points Redeemed = 0
etc.
Esto sugiere que se trata de meses sin actividad que han sido duplicados por error en el proceso de carga de datos.

# Conclusi√≥n:

Tras analizar las filas duplicadas en el dataset Customer Flight Activity, se identificaron 1864 registros repetidos exactamente (misma informaci√≥n en todas las columnas). La mayor√≠a de estas filas contienen datos con actividad nula: cero vuelos, cero puntos, cero distancia, etc.

Dado que estos duplicados:

- No aportan informaci√≥n nueva,
- Representan posibles errores de carga en meses sin actividad,
- pueden distorsionar los resultados del an√°lisis (por ejemplo, inflando los promedios o el n√∫mero total de registros por cliente),

Decido eliminarlos del dataset antes de continuar con la fase de an√°lisis y visualizaci√≥n. Esta limpieza mejora la calidad del dataset y permite obtener resultados m√°s precisos.


-----------------------------------

## üîé Diferencia entre `.nunique()` y `.unique()` en pandas

Durante la exploraci√≥n del DataFrame `df_flight`, hem utilizado el m√©todo `.nunique()` para obtener el n√∫mero de valores √∫nicos por columna.

---

### ‚úÖ `.nunique()`
- Devuelve **cu√°ntos valores √∫nicos hay** en cada columna (o en una columna espec√≠fica).
- Muy √∫til para detectar columnas con baja variabilidad o redundantes.

-----------------------

### csv Loyalty:

# .describe()

An√°lisis del resumen estad√≠stico (.describe().T) del dataset Customer Loyalty History
La funci√≥n df_loyalty.describe().T proporciona estad√≠sticas b√°sicas de las columnas num√©ricas. A continuaci√≥n se detallan los principales hallazgos:

1. Salary

Solo hay datos de salario para 12.499 clientes, lo que indica que faltan m√°s de 4.000 valores ‚Üí se deber√° tratar como valor nulo.
La media salarial es de 79.245‚ÄØ$, pero hay valores negativos (m√≠nimo: -58.486‚ÄØ$), lo cual no tiene sentido y debe considerarse un error.
El m√°ximo es de 407.228‚ÄØ$, lo que podr√≠a indicar un outlier o cliente de muy alto ingreso.

***  Tratamiento de salarios negativos ***

Durante la revisi√≥n de la columna Salary, se detectaron 20 valores negativos.
Aunque no es un n√∫mero elevado, se considera que estos valores corresponden a errores de carga, ya que el salario no puede ser negativo en un contexto realista.

Como en ejercicios anteriores se han tratado como valores absolutos, se decide mantener esa misma l√≥gica aqu√≠.

Adem√°s:

El n√∫mero de casos es muy bajo (20 de 16.737 registros), por lo que no distorsionar√° las estad√≠sticas.
As√≠ se evita eliminar informaci√≥n √∫til de esos clientes.
Decisi√≥n: transformar esos valores negativos a positivos utilizando .abs().

*** Gestion de nulos de Salary ***

üßºImputaci√≥n de valores nulos en la columna Salary
Tras analizar la distribuci√≥n de la columna Salary, observo que:

La media es 79.359‚ÄØ‚Ç¨ y la mediana es 73.455‚ÄØ‚Ç¨.
Hay cierta dispersi√≥n (desviaci√≥n t√≠pica de 34.750‚ÄØ‚Ç¨).
El valor m√°ximo es muy elevado (407.228‚ÄØ‚Ç¨), lo que sugiere posibles outliers.

Decido rellenar los valores nulos con la mediana, ya que:
- Es una medida robusta frente a valores extremos.
- Refleja mejor el comportamiento t√≠pico del salario en este contexto.


2. Cancellation Year y Cancellation Month

Solo 2.067 clientes tienen una fecha de cancelaci√≥n registrada.
Esto indica que la mayor√≠a siguen activos.
Las fechas y meses son correctos y no presentan errores aparentes.

# Gesti√≥n de nulos de las columnas Cancellation Year y Cancellation Month: 

Estas olumnas indican cuando el cliente dej√≥ su membres√≠a, por lo que si un cliente sigue activo, no tiene fecha de cancelacion y aparece como NaN

- ¬øQu√© hacer con estos nulos? En este caso, no se deben imputar ni eliminar, porque:
    1. Su ausencia tiene un significado: el cliente sigue siendo parte del programa.
    2. Eliminarlos ser√≠a perder informaci√≥n √∫til.
    3. Imputarlos ser√≠a inventar algo que no ocurri√≥

# üßæ Nueva columna: `Active Customer`

Se ha creado una nueva columna llamada `Active Customer` para indicar si un cliente sigue activo o no en el programa de fidelizaci√≥n.

- Se basa en la columna `Cancellation Year`:
  - Si el valor es `NaN`, significa que el cliente **sigue activo**.
  - Si hay un a√±o registrado, indica que **el cliente ha cancelado** su membres√≠a.

- Se han utilizado los valores `"Yes"` para clientes activos y `"No"` para clientes inactivos.









# .info()

*** ‚ÑπÔ∏è An√°lisis del .info() del dataset Customer Loyalty History ***
Al ejecutar df_loyalty.info(), se obtiene una visi√≥n general de la estructura y calidad de los datos. A continuaci√≥n se resumen los puntos clave:

1. Detecci√≥n de valores nulos

Aunque .info() no muestra expl√≠citamente los valores "NaN", se puede detectar su presencia comparando los valores en la columna Non-Null Count.
Salary: tiene solo 12.499 valores no nulos, por lo tanto hay 4.238 valores nulos.
Cancellation Year y Cancellation Month: tienen 2.067 valores no nulos, lo que indica que la mayor√≠a de los clientes no han cancelado su membres√≠a.

3. Tipos de datos (dtype)

Cancellation Year y Cancellation Month: aparecen como float64 porque contienen valores nulos. Aunque sem√°nticamente son enteros, pandas los convierte a float cuando hay nulos.
Si en alg√∫n momento se imputan o eliminan los nulos, se podr√≠an convertir a tipo entero usando Int64 (con soporte para nulos).

Conclusi√≥n:
Los datos est√°n en general bien tipados y organizados. Se identifican valores nulos relevantes en Salary y en las columnas de cancelaci√≥n, lo que deber√° ser tratado durante la limpieza. El resto de columnas presentan tipos adecuados para su an√°lisis posterior.


 *** Tipo de dato en columnas de cancelaci√≥n ***

Durante la exploraci√≥n inicial las columnas `Cancellation Year` y `Cancellation Month` aparecen como tipo `float64`, a pesar de que representan a√±os y meses (valores enteros).


 ¬øPor qu√© son `float64` y no `int64`?

Esto ocurre porque ambas columnas contienen valores `NaN`, los cuales pandas solo puede almacenar en columnas de tipo `float` (en su comportamiento por defecto).  
Los tipos `int` normales (`int64`) **no pueden contener `NaN`**, por lo que se convierte todo a `float64` autom√°ticamente.


Decido **mantener ambas columnas como `float64`**, ya que:

- Los `NaN` tienen un significado importante (clientes activos).
- No es necesario cambiar el tipo para el an√°lisis actual.
- Podria usar un tipo especial llamado "Int64" (con may√∫scula), que s√≠ acepta NaN pero forzar la conversi√≥n a `int` podr√≠a provocar errores o p√©rdida de informaci√≥n.

Si en un futuro se desea trabajar con enteros y permitir `NaN`, podr√≠a considerarse convertirlas a `Int64` (entero "nullable" de pandas).


# .nunique() 

An√°lisis de valores √∫nicos con .nunique()
Se ejecut√≥ df_loyalty.nunique() para conocer cu√°ntos valores √∫nicos existen por columna en el dataset. Este an√°lisis permite identificar columnas con poca variaci√≥n, posibles identificadores √∫nicos, y variables √∫tiles para segmentar o agrupar.

1. Country ‚Üí 1 √∫nico valor. Todos los clientes pertenecen al mismo pa√≠s. Esta columna no aporta valor anal√≠tico y puede eliminarse.

Conclusi√≥n:
La mayor√≠a de columnas muestran una variabilidad adecuada para el an√°lisis.  Eliminar la columna Country (sin variaci√≥n), y revisar si Postal Code aporta valor adicional respecto a ciudad y provincia.


------------------------------

### üîó Uni√≥n de los datasets: vuelos + informaci√≥n de cliente

Decidido limpiar primero cada dataset por separado (df_loyalty y df_flight) antes de unirlos, con el objetivo de:
- Corregir valores err√≥neos (como salarios negativos).
- Imputar nulos con la l√≥gica adecuada seg√∫n cada contexto.
- Eliminar duplicados exactos que no aportaban informaci√≥n.
As√≠ aseguro que el merge se hace sobre datos limpios y consistentes, evitando arrastrar errores al DataFrame final.

Para combinar la informaci√≥n de comportamiento de vuelo (`df_flight`) con los datos personales y demogr√°ficos (`df_loyalty`), se realiza una uni√≥n mediante la columna com√∫n `Loyalty Number`.


### üîó Uni√≥n eficiente de los datasets

Se realiza la uni√≥n de los dos conjuntos de datos `df_flight` (actividad de vuelo) y `df_loyalty` (informaci√≥n del cliente), utilizando la clave com√∫n `Loyalty Number`.

Se emplea un **inner join**, ya que se considera la forma m√°s eficiente para este an√°lisis:
- Solo conserva las filas que est√°n presentes en ambos datasets.
- Elimina datos incompletos o no vinculados.
- Optimiza el tama√±o del DataFrame resultante.

df_merged = pd.merge(df_flight, df_loyalty, on='Loyalty Number', how='inner')

-------------------------

### VISUALIZACION: 

# 1. ¬øComo se distribuye la cantidad de vuelos reservados por mes durante el a√±o?

# üìä Distribuci√≥n de vuelos reservados por mes

El objetivo de esta visualizaci√≥n es analizar **c√≥mo var√≠a la cantidad de vuelos reservados (`Flights Booked`) a lo largo del a√±o**, agrupando los datos por mes.

Selecciono el gr√°fico de barras por los siguientes motivos:

- Permite **comparar cantidades entre categor√≠as** discretas (en este caso, los meses del a√±o).
- Muestra con claridad las diferencias entre los meses.

### üìä An√°lisis: Distribuci√≥n de vuelos reservados por mes

Tras representar gr√°ficamente la cantidad total de vuelos reservados por mes, se observan los siguientes patrones:

---

# üîº Meses con mayor n√∫mero de vuelos reservados:

En la visualizaci√≥n se aprecia claramente una estacionalidad en el comportamiento de los usuarios.

Los meses de verano, especialmente julio, seguido por junio y agosto, destacan como los per√≠odos con mayor volumen de vuelos reservados. Este patr√≥n es coherente con las vacaciones estivales, tanto escolares como laborales, en las que muchas personas aprovechan para viajar, lo que provoca un aumento significativo de la demanda.

Otro pico relevante se observa en diciembre, mes asociado a las celebraciones navide√±as y de fin de a√±o, durante el cual tambi√©n es habitual que se realicen desplazamientos familiares o de ocio.

Por otro lado, los meses de enero y febrero presentan los niveles m√°s bajos de reservas. Esto puede deberse a la conocida "cuesta de enero", un periodo posterior a las fiestas en el que muchas personas ajustan su presupuesto. Adem√°s, el clima invernal podr√≠a influir negativamente en las decisiones de viaje, reduciendo as√≠ la demanda.

En conjunto, el gr√°fico refleja c√≥mo los h√°bitos de viaje var√≠an a lo largo del a√±o, estando fuertemente condicionados por factores como las vacaciones, las festividades y el contexto econ√≥mico


## 2. ¬øExiste una relaci√≥n entre la distancia de los vuelos y los puntos acumulados por los cliente?


# ‚úÖ Interpretaci√≥n:

En la visualizaci√≥n se observa una **relaci√≥n lineal positiva muy clara y marcada**.  
Los puntos siguen trayectorias diagonales bien definidas, lo cual indica que a **mayor distancia recorrida**, los clientes **acumulan m√°s puntos**.

Esta relaci√≥n es l√≥gica dentro del contexto de un programa de fidelizaci√≥n, donde los puntos suelen asignarse en funci√≥n de la distancia volada.

Existe una **correlaci√≥n directa, sistem√°tica y consistente** entre ambas variables. Esto sugiere que la asignaci√≥n de puntos por vuelo se realiza siguiendo una f√≥rmula clara y estable en funci√≥n de la distancia.

## 3. ¬øCu√°l es la distribuci√≥n de los clientes por provincia o estado?

He utilizado un gr√°fico de barras horizontales para visualizar la distribuci√≥n de clientes √∫nicos por provincia.
El gr√°fico muestra una **distribuci√≥n claramente desigual** entre las diferentes regiones. Las provincias con mayor n√∫mero de clientes son:

- **Ontario**, con diferencia, es la provincia con m√°s clientes registrados.
- Le siguen **British Columbia** y **Quebec**, tambi√©n con una alta concentraci√≥n de clientes.

Por otro lado, provincias como **Yukon**, **Newfoundland** y **Prince Edward Island** tienen una representaci√≥n significativamente menor.

Este tipo de distribuci√≥n puede deberse a varios factores como la densidad de poblaci√≥n, la infraestructura a√©rea disponible o el enfoque comercial de la compa√±√≠a en determinadas regiones.

La mayor parte de los clientes se concentra en unas pocas provincias, lo cual puede ser clave para orientar decisiones de negocio, campa√±as de fidelizaci√≥n o expansi√≥n de servicios.


## 4.  ¬øC√≥mo se compara el salario promedio entre los diferentes niveles educativos de los clientes?

El gr√°fico muestra c√≥mo var√≠a el salario promedio de los clientes en funci√≥n de su nivel educativo. Se observa una **tendencia clara**: a mayor nivel educativo, mayor salario promedio.

- Los clientes con **Doctorado** son los que presentan el salario promedio m√°s alto.
- Les siguen aquellos con **Master**, tambi√©n con ingresos elevados.
- **Bachelor** y **College** muestran salarios similares, en un rango medio.
- El grupo **High School or Below** tiene el salario promedio m√°s bajo.

Esta distribuci√≥n es coherente con lo esperado, reflejando que **la formaci√≥n acad√©mica tiene un impacto positivo en los ingresos** de los clientes.

# 5.  ¬øCu√°l es la proporci√≥n de clientes con diferentes tipos de tarjetas de fidelidad?

Para resolver este ejercicio, parto de la premisa de que cada cliente puede aparecer m√∫ltiples veces en el DataFrame original (`df_unido`) debido al registro mensual de su actividad, sin embargo, el tipo de tarjeta de fidelidad (`Loyalty Card`) **no cambia** para un mismo cliente, por lo que **es fundamental contar cada cliente una sola vez**.


